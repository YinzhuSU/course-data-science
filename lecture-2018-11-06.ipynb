{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Introduction to Neural Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "In these notes, we go over some basic examples in order to understand how artificial neural networks can be viewed as an extension or variant of existing classification and linear regression techniques. We also provide an example of how to train a neural network using a common library."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Gradient descent: simplest possible examples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "**Example**: Suppose we have a data set consisting of a single point $(x, y) = (2, 6)$. We wish to find a model for this data from the space of linear functions of the form $y = \\beta \\cdot x$. Thus, we need to find the parameter $\\beta$.\n",
    "\n",
    "We can proceed by setting up the equation in the usual way by plugging the data point into the equation (if we had more data, we would have a system of equations):\n",
    "\n",
    "$$y = \\beta \\cdot x$$\n",
    "$$6 = \\beta \\cdot 2$$\n",
    "\n",
    "Rather than solve the above directly using algebra, suppose we instead wish to use calculus. We can define an **error** function $\\varepsilon(\\beta)$ in terms of the unknown parameter $\\beta$:\n",
    "\n",
    "\n",
    "$$\\varepsilon(\\beta) = (\\beta \\cdot x - y)^2$$\n",
    "$$\\varepsilon(\\beta) = (\\beta \\cdot 2 - 6)^2$$\n",
    "\n",
    "We can expand the above:\n",
    "\n",
    "\\begin{eqnarray*}\n",
    "\\varepsilon(\\beta) & = & (x^2 \\beta^2) - 2\\cdot (y \\cdot x \\cdot \\beta) + (y^2) \\\\\n",
    "\\varepsilon(\\beta) &=& 4 \\beta^2 - 6 \\cdot 2 \\cdot \\beta - 6 \\cdot 2 \\cdot \\beta + 6^2 \\\\\n",
    "                   &=& 4 \\beta^2 - 24 \\beta + 36\n",
    "\\end{eqnarray*}\n",
    "\n",
    "Note that the function $\\varepsilon(\\beta)$ actually represents a parabola. If we want to **minimize** the error that our choice of parameter $\\beta$ introduces into the model (or, equivalently, if we want to minimize the value of $\\varepsilon(\\beta)$), we can find the minimum point on the parabola. This can be done by setting the derivative of $\\varepsilon$ with respect to $\\beta$ to $0$, since the bottom of the parabola has a slope of $0$.\n",
    "\n",
    "\\begin{eqnarray*}\n",
    "\\varepsilon'(\\beta) &=& \\frac{d\\varepsilon}{d\\beta} = 2 \\cdot x^2 \\cdot \\beta - 2 \\cdot y \\cdot x \\\\\n",
    "\\varepsilon'(\\beta) &=& \\frac{d\\varepsilon}{d\\beta} = 2 \\cdot 4 \\cdot \\beta - 24 \\\\\n",
    "                    &=& \\frac{d\\varepsilon}{d\\beta} = 8\\beta - 24\n",
    "\\end{eqnarray*}\n",
    "\n",
    "Thus, we solve for the $\\beta$ that minimizes the error.\n",
    "\n",
    "\\begin{eqnarray*}\n",
    "0 &=& \\varepsilon'(\\beta) \\\\\n",
    "0 &=& 8\\beta - 24 \\\\\n",
    "24 &=& 8 \\beta \\\\\n",
    "\\beta &=& 3\n",
    "\\end{eqnarray*}\n",
    "\n",
    "We could take yet another approach instead of directly solving $\\varepsilon'(\\beta) = 0$. Suppose we want to **guess** some $\\beta^\\ast$ and then adjust it depending on the slope of the error at our chosen $\\beta^\\ast$?\n",
    "\n",
    "As long as we know that $\\varepsilon$ is a parabola (or, more generally, that it is convex), we can do so by computing $\\varepsilon'(\\beta^\\ast)$ and then updating our guess based on the slope. Suppose $\\beta^\\ast = 4$. Then we have:\n",
    "\n",
    "\\begin{eqnarray*}\n",
    "\\varepsilon'(\\beta^\\ast) &=& \\varepsilon'(4) \\\\\n",
    "                         &=& 8 \\cdot 4 - 24 \\\\\n",
    "  &=& 32 - 24 \\\\\n",
    "  &=& 8\n",
    "\\end{eqnarray*}\n",
    "\n",
    "Now suppose $\\beta^\\ast = 2$. Then we have:\n",
    "\n",
    "\\begin{eqnarray*}\n",
    "\\varepsilon'(\\beta^\\ast) &=& \\varepsilon'(2) \\\\\n",
    "                         &=& 8 \\cdot 2 - 24 \\\\\n",
    "  &=& 16 - 24 \\\\\n",
    "  &=& -8\n",
    "\\end{eqnarray*}\n",
    "\n",
    "So one approach we could take is to compute $\\varepsilon'(\\beta^\\ast)$ and then update our guess $\\beta^\\ast$ based on some version of this slope (e.g., weighted by an update coefficient $a$):\n",
    "\n",
    "$$\\beta_{j+1}^\\ast = \\beta_j^\\ast - a \\cdot \\varepsilon'(\\beta_j^\\ast)$$\n",
    "\n",
    "You will notice that for $a = \\frac{1}{8}$, we would converge from a guess of $2$ or $4$ onto the correct value $3$ with only one update step. On the other hand, notice that for a poorly chosen update coefficient $a$, our guess would actually become progressively worse!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "\n",
    "**Example**: Suppose we have a data set consisting of two points $(x_1, y_1)$ and $(x_2, y_2)$. We can expand the approach from the above example. The system of equations would be:\n",
    "\n",
    "$$y_1 = \\beta \\cdot x_1$$\n",
    "$$y_2 = \\beta \\cdot x_2$$\n",
    "\n",
    "The error function could be the typical sum of squares:\n",
    "\n",
    "\\begin{eqnarray*}\n",
    "\\varepsilon(\\beta) & = & (\\beta x_1 - y_1)^2 + (\\beta x_2 - y_2)^2 \\\\\n",
    "                   & = & \\sum_{i = 1}^{2} (\\beta x_i - y_i)^2\n",
    "\\end{eqnarray*}\n",
    "\n",
    "We can expand the above as we did in the example above:\n",
    "\n",
    "\\begin{eqnarray*}\n",
    "\\varepsilon(\\beta) &=& \\sum_{i = 1}^{2} (x_i^2 \\beta^2 - 2 y_i x_i \\beta + y_i^2) \\\\\n",
    "\\varepsilon(\\beta) &=& \\sum_{i = 1}^{2} x_i^2 \\beta^2 - \\sum_{i = 1}^{2} 2 y_i x_i \\beta + \\sum_{i = 1}^{2} y_i^2 \\\\\n",
    "                   &=& \\beta^2 \\sum_{i = 1}^{2} x_i^2 - \\beta \\sum_{i = 1}^{2} 2 y_i x_i + \\sum_{i = 1}^{2} y_i^2 \\\\\n",
    "                   &=& \\beta^2 (...) - \\beta (...) + (...)\n",
    "\\end{eqnarray*}\n",
    "\n",
    "Notice that in the above, the terms $\\beta^2$ and $\\beta$ have been isolated using algebra, and their coefficients are a function of the data itself. Thus, from this point forward the problem can be solved in exactly the same way as was done in the previous example."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "**Example**: Suppose we have a situation with some data set $(x_1,y_1),...,(x_n,y_n)$ and two model parameters $\\alpha$ and $\\beta$. Then our system of equations would consist of equations of the form:\n",
    "\n",
    "$$y_i = \\beta x_i + \\alpha$$\n",
    "\n",
    "We can define an error function in this case, as well, and then isolate the $\\alpha$ and $\\beta$ factors from the terms that contain the actual data values:\n",
    "\n",
    "\\begin{eqnarray*}\n",
    "\\varepsilon(\\beta, \\alpha) & = & \\sum_{i} ((\\beta x_i + \\alpha) - y_i)^2 \\\\\n",
    "                   & = & \\sum_{i} ((\\beta x_i + \\alpha)^2 - 2 y_i (\\beta x_i + \\alpha) + y_i^2) \\\\\n",
    "                   & = & \\sum_{i} ((\\beta^2 x_i^2 + 2 \\alpha \\beta x_i + \\alpha^2) - 2 y_i (\\beta x_i + \\alpha) + y_i^2) \\\\\n",
    "                   & = & \\sum_{i} (\\beta^2 x_i^2 + 2 \\alpha \\beta x_i + \\alpha^2 - 2 y_i \\beta x_i - 2 y_i \\alpha + y_i^2) \\\\\n",
    "                   & = & \\beta^2 (\\sum_{i} x_i^2) + 2 \\alpha \\beta (\\sum_{i} x_i) + \\alpha^2 (\\sum_{i} 1)  - 2 \\beta (\\sum_{i} y_i x_i) - 2 \\alpha (\\sum_{i} y_i) + (\\sum_i y_i^2)  \n",
    "\\end{eqnarray*}\n",
    "\n",
    "We can now compute the derivatives of $\\varepsilon$ with respect to both $\\alpha$ and $\\beta$:\n",
    "\n",
    "\\begin{eqnarray*}\n",
    "\\frac{\\partial\\varepsilon(\\beta, \\alpha)}{\\partial\\beta} & = & 2 \\beta (\\sum_{i} x_i^2) + 2 \\alpha (\\sum_{i} x_i) - 2 (\\sum_{i} y_i x_i)\\\\\n",
    "\\frac{\\partial\\varepsilon(\\beta, \\alpha)}{\\partial\\alpha} & = & 2 \\beta (\\sum_{i} x_i) + 2 \\alpha (\\sum_{i} 1) - 2 (\\sum_{i} y_i)\n",
    "\\end{eqnarray*}\n",
    "\n",
    "We sometimes write $\\nabla\\varepsilon(\\beta, \\alpha) = (\\frac{\\partial\\varepsilon(\\beta, \\alpha)}{\\partial\\beta}, \\frac{\\partial\\varepsilon(\\beta, \\alpha)}{\\partial\\alpha})$ or $\\nabla\\varepsilon = (\\frac{\\partial\\varepsilon}{\\partial\\beta}, \\frac{\\partial\\varepsilon}{\\partial\\alpha})$ .\n",
    "\n",
    "If we start with guesses $(\\beta^\\ast, \\alpha^\\ast)$ for our parameters, we can then compute $\\nabla \\varepsilon(\\beta^\\ast, \\alpha^\\ast)$ to obtain a gradient vector. We can then add a weighted version of this vector to our original guess using vector addition. This yields an update rule for each iteration $i$ of a gradient descent algorithm:\n",
    "\n",
    "$$(\\beta_{j+1}^\\ast, \\alpha_{j+1}^\\ast) = (\\beta_{j}^\\ast, \\alpha_{j}^\\ast) - a \\cdot \\nabla \\varepsilon(\\beta_j^\\ast, \\alpha_j^\\ast)$$\n",
    "\n",
    "Finally, notice that in our examples the summation has always ranged over all data points. However, this is not necessary. We could instead perform each of the above iterations by computing $\\varepsilon(\\beta_j^\\ast, \\alpha_j^\\ast)$ over only **some** of the data. For each iteration, we could introduce a new subset of the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## TensorFlow example: classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# This notebook modified by Adam Smith\n",
    "\n",
    "# Original version copyright 2016 The TensorFlow Authors. All Rights Reserved.\n",
    "#\n",
    "#  Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "#  you may not use this file except in compliance with the License.\n",
    "#  You may obtain a copy of the License at\n",
    "#\n",
    "#   http://www.apache.org/licenses/LICENSE-2.0\n",
    "\n",
    "\"\"\"An Example of a DNNClassifier for the Iris dataset.\"\"\"\n",
    "\n",
    "import argparse\n",
    "import tensorflow as tf\n",
    "\n",
    "import iris_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "# This code can be modified to read arguments from the command line, when appropriate. \n",
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument('--batch_size', default=100, type=int, help='batch size')\n",
    "parser.add_argument('--train_steps', default=1000, type=int,\n",
    "                    help='number of training steps')\n",
    "args = parser.parse_args([])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "First, we load the data into dataframes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fetch the data.\n",
    "(train_x, train_y), (test_x, test_y) = iris_data.load_data()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "We can examine the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.frame.DataFrame"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(train_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SepalLength</th>\n",
       "      <th>SepalWidth</th>\n",
       "      <th>PetalLength</th>\n",
       "      <th>PetalWidth</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6.4</td>\n",
       "      <td>2.8</td>\n",
       "      <td>5.6</td>\n",
       "      <td>2.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5.0</td>\n",
       "      <td>2.3</td>\n",
       "      <td>3.3</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.9</td>\n",
       "      <td>2.5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>1.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.7</td>\n",
       "      <td>3.8</td>\n",
       "      <td>1.7</td>\n",
       "      <td>0.3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   SepalLength  SepalWidth  PetalLength  PetalWidth\n",
       "0          6.4         2.8          5.6         2.2\n",
       "1          5.0         2.3          3.3         1.0\n",
       "2          4.9         2.5          4.5         1.7\n",
       "3          4.9         3.1          1.5         0.1\n",
       "4          5.7         3.8          1.7         0.3"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.series.Series"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    2\n",
       "1    1\n",
       "2    2\n",
       "3    0\n",
       "4    0\n",
       "Name: Species, dtype: int64"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_y.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "The test/train split is 80/20."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(480, 120)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(train_x.size, test_x.size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "We now instantiate the classifer. This object is specific to discrete classification and can be customized in terms of:\n",
    "- features,\n",
    "- network structure,\n",
    "- number of classes, and\n",
    "- (optionally) many other options (activitation function, optimization methods, and so on).\n",
    "\n",
    "Defaults worth knowing: \n",
    "- activitation function is ReLU, and\n",
    "- \"dropout\" regularization is not used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SepalLength _NumericColumn(key='SepalLength', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None)\n",
      "SepalWidth _NumericColumn(key='SepalWidth', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None)\n",
      "PetalLength _NumericColumn(key='PetalLength', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None)\n",
      "PetalWidth _NumericColumn(key='PetalWidth', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None)\n",
      "\n",
      "INFO:tensorflow:Using default config.\n",
      "WARNING:tensorflow:Using temporary folder as model directory: /var/folders/h_/s381b4dj4cx2ywclhcp_3v4m0000gn/T/tmpbz5rnm50\n",
      "INFO:tensorflow:Using config: {'_model_dir': '/var/folders/h_/s381b4dj4cx2ywclhcp_3v4m0000gn/T/tmpbz5rnm50', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x1255f3b70>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Feature columns describe how to use the input.\n",
    "# We are adding one numeric feature for each column of the training data.\n",
    "my_feature_columns = []\n",
    "for key in train_x.keys():\n",
    "    fc = tf.feature_column.numeric_column(key=key)\n",
    "    print(key, fc)\n",
    "    my_feature_columns.append(fc)\n",
    "\n",
    "print()\n",
    "\n",
    "# Build 2 hidden layer DNN with 10, 10 units respectively.\n",
    "classifier = tf.estimator.DNNClassifier(\n",
    "    feature_columns = my_feature_columns,\n",
    "    \n",
    "    # Two hidden layers of 10 nodes each.\n",
    "    hidden_units = [10, 10],\n",
    "    \n",
    "    # The model must choose between 3 classes.\n",
    "    n_classes=3,\n",
    "    \n",
    "    ## We can also set the directory where model information will be saved.\n",
    "    ##model_dir='models/iris'\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensorflow.python.estimator.canned.dnn.DNNClassifier"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(classifier)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "We are now ready to train. We pass the input to the classifer as a function. That function takes no arguments and returns a `tf.data.Dataset` object. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# This code is copied from iris_data.py.\n",
    "\n",
    "def train_input_fn(features, labels, batch_size):\n",
    "    \"\"\"An input function for training\"\"\"\n",
    "    # Convert the inputs to a Dataset.\n",
    "    dataset = tf.data.Dataset.from_tensor_slices((dict(features), labels))\n",
    "\n",
    "    # Shuffle, repeat, and batch the examples.\n",
    "    dataset = dataset.shuffle(1000).repeat().batch(batch_size)\n",
    "\n",
    "    # Return the dataset.\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Saving checkpoints for 0 into /var/folders/h_/s381b4dj4cx2ywclhcp_3v4m0000gn/T/tmpbz5rnm50/model.ckpt.\n",
      "INFO:tensorflow:loss = 124.93739, step = 1\n",
      "INFO:tensorflow:global_step/sec: 281.448\n",
      "INFO:tensorflow:loss = 21.743896, step = 101 (0.357 sec)\n",
      "INFO:tensorflow:global_step/sec: 441.261\n",
      "INFO:tensorflow:loss = 13.786755, step = 201 (0.228 sec)\n",
      "INFO:tensorflow:global_step/sec: 388.666\n",
      "INFO:tensorflow:loss = 10.441718, step = 301 (0.256 sec)\n",
      "INFO:tensorflow:global_step/sec: 467.135\n",
      "INFO:tensorflow:loss = 6.570615, step = 401 (0.214 sec)\n",
      "INFO:tensorflow:global_step/sec: 527.335\n",
      "INFO:tensorflow:loss = 10.371038, step = 501 (0.189 sec)\n",
      "INFO:tensorflow:global_step/sec: 540.657\n",
      "INFO:tensorflow:loss = 5.057136, step = 601 (0.185 sec)\n",
      "INFO:tensorflow:global_step/sec: 444.644\n",
      "INFO:tensorflow:loss = 4.938775, step = 701 (0.226 sec)\n",
      "INFO:tensorflow:global_step/sec: 467.922\n",
      "INFO:tensorflow:loss = 4.135901, step = 801 (0.213 sec)\n",
      "INFO:tensorflow:global_step/sec: 516.399\n",
      "INFO:tensorflow:loss = 5.5098014, step = 901 (0.194 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 1000 into /var/folders/h_/s381b4dj4cx2ywclhcp_3v4m0000gn/T/tmpbz5rnm50/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 5.5397415.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.estimator.canned.dnn.DNNClassifier at 0x1253eca20>"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier.train(\n",
    "    input_fn = lambda:iris_data.train_input_fn(train_x, train_y,\n",
    "                                                 args.batch_size),\n",
    "    steps = args.train_steps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "The most straightforward way to construct input functions is directly from a dataframe (can also do this from a numpy array):\n",
    "\n",
    "```python\n",
    "import pandas as pd\n",
    "# pandas input_fn.\n",
    "my_input_fn = tf.estimator.inputs.pandas_input_fn(\n",
    "    x=pd.DataFrame({\"x\": x_data}),\n",
    "    y=pd.Series(y_data),\n",
    "    ...)\n",
    "```\n",
    "\n",
    "You can see and other examples here: \n",
    " https://www.tensorflow.org/versions/r1.3/get_started/input_fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['dnn/hiddenlayer_0/bias',\n",
       " 'dnn/hiddenlayer_0/bias/t_0/Adagrad',\n",
       " 'dnn/hiddenlayer_0/kernel',\n",
       " 'dnn/hiddenlayer_0/kernel/t_0/Adagrad',\n",
       " 'dnn/hiddenlayer_1/bias',\n",
       " 'dnn/hiddenlayer_1/bias/t_0/Adagrad',\n",
       " 'dnn/hiddenlayer_1/kernel',\n",
       " 'dnn/hiddenlayer_1/kernel/t_0/Adagrad',\n",
       " 'dnn/logits/bias',\n",
       " 'dnn/logits/bias/t_0/Adagrad',\n",
       " 'dnn/logits/kernel',\n",
       " 'dnn/logits/kernel/t_0/Adagrad',\n",
       " 'global_step']"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier.get_variable_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.44063115, -0.23042291,  0.13243337,  0.8365632 ,  0.36168227,\n",
       "         0.00820287,  0.35834   ,  0.17601633,  0.29611564,  0.234959  ],\n",
       "       [-0.30628192, -1.0811728 , -0.5592357 ,  1.0111309 , -0.7359063 ,\n",
       "        -0.85464525,  0.7836679 , -0.5366037 ,  0.20144102,  0.41184592],\n",
       "       [ 0.57232094, -0.0753327 ,  0.3342247 ,  0.01109344,  0.01686647,\n",
       "         0.4699366 ,  0.46981207, -0.3487868 , -0.5416549 , -0.4551163 ],\n",
       "       [-0.00952396,  0.91267526,  0.48889056, -0.5507718 ,  0.5058314 ,\n",
       "         0.4080208 , -0.44290552,  0.08135599,  0.3890145 ,  0.11176193]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We can inspect the weights and biases of the resulting model.\n",
    "classifier.get_variable_value('dnn/hiddenlayer_0/kernel')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2018-11-06-22:20:31\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from /var/folders/h_/s381b4dj4cx2ywclhcp_3v4m0000gn/T/tmpbz5rnm50/model.ckpt-1000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Finished evaluation at 2018-11-06-22:20:31\n",
      "INFO:tensorflow:Saving dict for global step 1000: accuracy = 0.96666664, average_loss = 0.06147208, global_step = 1000, loss = 1.8441625\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 1000: /var/folders/h_/s381b4dj4cx2ywclhcp_3v4m0000gn/T/tmpbz5rnm50/model.ckpt-1000\n",
      "\n",
      "Test set accuracy: 0.967\n",
      "\n"
     ]
    }
   ],
   "source": [
    "eval_result = classifier.evaluate(\n",
    "        input_fn = lambda:iris_data.eval_input_fn(test_x, test_y,\n",
    "                                                  args.batch_size))\n",
    "\n",
    "print('\\nTest set accuracy: {accuracy:0.3f}\\n'.format(**eval_result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy :  0.96666664\n",
      "average_loss :  0.06147208\n",
      "loss :  1.8441625\n",
      "global_step :  1000\n"
     ]
    }
   ],
   "source": [
    "# eval_result is a dictionary with a few basic statistics\n",
    "for key in eval_result.keys():\n",
    "    print(key, \": \", eval_result[key])"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
